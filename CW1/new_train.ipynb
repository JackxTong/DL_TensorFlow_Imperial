{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend after setting: torch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "# set backend\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "import keras\n",
    "print(\"Backend after setting:\", keras.config.backend())\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# Check GPU visibility\n",
    "# print(\"TensorFlow GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "PyTorch Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self, device_id=0):\n",
    "        self.device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set device to GPU 1\n",
    "config = Config(device_id=1)\n",
    "device = config.device\n",
    "torch.cuda.set_device(config.device.index)\n",
    "print(torch.cuda.current_device()) \n",
    "print(\"PyTorch Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,691,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │    \u001b[38;5;34m25,691,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)           │     \u001b[38;5;34m1,032,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,953,088</span> (102.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,953,088\u001b[0m (102.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,950,336</span> (102.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,950,336\u001b[0m (102.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> (10.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,752\u001b[0m (10.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import (Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, \n",
    "                          Flatten, Dense, Dropout, Lambda)\n",
    "from keras.initializers import HeNormal\n",
    "import keras.ops as K\n",
    "\n",
    "def get_model(hidden_units, output_units, input_shape, rate, l2_coeff=1e-5):\n",
    "    \"\"\"\n",
    "    Creates a face verification model that outputs normalized embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential([Input(shape=input_shape)])\n",
    "\n",
    "    # --- Convolutional blocks / Feature extraction backbone ---\n",
    "\n",
    "    # note we use he kaiming initialization for the weights\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer=HeNormal(),\n",
    "                     kernel_regularizer=regularizers.l2(l2_coeff)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 2nd block\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer=HeNormal(),\n",
    "                     kernel_regularizer=regularizers.l2(l2_coeff)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 3rd block\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer=HeNormal(),\n",
    "                     kernel_regularizer=regularizers.l2(l2_coeff)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # --- Fully connected layers ---\n",
    "    for units in hidden_units:\n",
    "        model.add(Dense(units, kernel_initializer=HeNormal(),\n",
    "                        kernel_regularizer=regularizers.l2(l2_coeff)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(rate))\n",
    "\n",
    "    # --- Output layer for classification ---\n",
    "    # outputs 8000-probability vector\n",
    "    model.add(Dense(output_units, kernel_initializer=HeNormal(), activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(\n",
    "    hidden_units=[1024, 128],\n",
    "    output_units=8000, # 8000 identities\n",
    "    input_shape=(112, 112, 3),\n",
    "    rate=0.5\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "class PytorchFaceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A single unified class that:\n",
    "      - Loads up to `max_images_per_identity` images from each identity folder.\n",
    "      - Optionally uses `sample_indexes` for train/val slicing.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, dataset_path, identities,\n",
    "        max_images_per_identity=10,\n",
    "        sample_indexes=None,\n",
    "        classes_per_batch=None,\n",
    "        samples_per_class=None\n",
    "    ):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.identities = identities\n",
    "        self.max_images_per_identity = max_images_per_identity\n",
    "        self.sample_indexes = sample_indexes\n",
    "        self.classes_per_batch = classes_per_batch\n",
    "        self.samples_per_class = samples_per_class\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []  # We'll group by label = idx in `identities`\n",
    "        \n",
    "        # Gather all images & labels\n",
    "        for idx, identity in enumerate(identities):\n",
    "            identity_folder = os.path.join(dataset_path, identity)\n",
    "            if not os.path.isdir(identity_folder):\n",
    "                continue  # skip if folder doesn't exist\n",
    "\n",
    "            image_files = sorted(os.listdir(identity_folder))\n",
    "            # Take up to max_images_per_identity images\n",
    "            selected_images = image_files[:max_images_per_identity]\n",
    "            for img_name in selected_images:\n",
    "                self.image_paths.append(os.path.join(identity_folder, img_name))\n",
    "                self.labels.append(idx)\n",
    "\n",
    "        # sample_indexes is train_indices or val_indices\n",
    "        if self.sample_indexes is not None:\n",
    "            self.image_paths = [self.image_paths[i] for i in self.sample_indexes]\n",
    "            self.labels = [self.labels[i] for i in self.sample_indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Load image, convert to RGB, resize to (112, 112)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize((112, 112), resample=Image.BILINEAR)\n",
    "        # Normalize to [0, 1]\n",
    "        img = np.array(img, dtype=np.float32) / 255.0  # shape: (112, 112, 3)\n",
    "\n",
    "        img_tensor = torch.from_numpy(img)  # currently (112, 112, 3)\n",
    "\n",
    "        return img_tensor, label\n",
    "\n",
    "    def get_dataloader(self, batch_size=128, shuffle=True, num_workers=4):\n",
    "        # If we have custom-batch parameters set, build the custom sampler\n",
    "        if self.classes_per_batch is not None and self.samples_per_class is not None:\n",
    "            return DataLoader(\n",
    "                self,\n",
    "                batch_sampler=self._BatchSampler(\n",
    "                    self.labels,\n",
    "                    self.classes_per_batch,\n",
    "                    self.samples_per_class\n",
    "                ),\n",
    "                num_workers=num_workers\n",
    "            )\n",
    "        else:\n",
    "            return DataLoader(\n",
    "                self,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                num_workers=num_workers\n",
    "            )\n",
    "\n",
    "    class _BatchSampler(Sampler):\n",
    "        \"\"\"\n",
    "        Ensures each batch contains `classes_per_batch` classes, each has\n",
    "        `samples_per_class` samples or fewer.\n",
    "        \"\"\"\n",
    "        def __init__(self, labels, classes_per_batch, samples_per_class):\n",
    "            self.labels = labels\n",
    "            self.classes_per_batch = classes_per_batch\n",
    "            self.samples_per_class = samples_per_class\n",
    "\n",
    "            # Group indices by class\n",
    "            self.class_to_indices = {}\n",
    "            for idx, label in enumerate(labels):\n",
    "                self.class_to_indices.setdefault(label, []).append(idx)\n",
    "\n",
    "            # Keep list of all classes for shuffling each epoch\n",
    "            self.all_classes = list(self.class_to_indices.keys())\n",
    "\n",
    "        def __iter__(self):\n",
    "            '''Defines how the batch indices are generated.'''\n",
    "            random.shuffle(self.all_classes) # Shuffle list of all labels each epoch\n",
    "\n",
    "            # We'll chunk the shuffled class list in groups of 'classes_per_batch'\n",
    "\n",
    "            # loop over shuffled classes in chunks of 'classes_per_batch'\n",
    "            # e.g. 8000 classes, 10 class per epoch, so 800 iterations\n",
    "            for start in range(0, len(self.all_classes), self.classes_per_batch):\n",
    "                chunk_classes = self.all_classes[start:start + self.classes_per_batch]\n",
    "                \n",
    "                batch_indices = []\n",
    "                for cls in chunk_classes: # collect sample indices for each class\n",
    "                    idx_list = self.class_to_indices[cls] # map label to indices\n",
    "\n",
    "                    # if a class has enough samples, sample 'samples_per_class' indices\n",
    "                    # otherwise, take all indices\n",
    "                    if len(idx_list) >= self.samples_per_class:\n",
    "                        chosen = random.sample(idx_list, self.samples_per_class)\n",
    "                    else:\n",
    "                        chosen = idx_list  # class is smaller than desired\n",
    "                    batch_indices.extend(chosen)\n",
    "\n",
    "                yield batch_indices # move to dataloader\n",
    "\n",
    "        def __len__(self):\n",
    "            ''' computes how many batches are needed to cover all classes '''\n",
    "            # e.g. 8000 class, 10 class per batch, so (8010-1) // 10 = 800\n",
    "            return (len(self.all_classes) + self.classes_per_batch - 1) // self.classes_per_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identities in dataset: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib64/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([83, 112, 112, 3]), Labels shape: torch.Size([83])\n",
      "Unique labels in this batch: 10\n"
     ]
    }
   ],
   "source": [
    "# # Load dataset identities\n",
    "import numpy as np\n",
    "dataset_path = \"data/casia-webface\"\n",
    "identities = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "print(\"Number of identities in dataset:\", len(identities))\n",
    "indices = np.arange(80000)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_torch_dataset = PytorchFaceDataset(dataset_path, identities, \n",
    "                                         max_images_per_identity=10, \n",
    "                                         sample_indexes=train_indices,\n",
    "                                         classes_per_batch=10,   # each batch will pick 10 classes\n",
    "                                        samples_per_class=10) # each class has 10 samples\n",
    "train_loader = train_torch_dataset.get_dataloader(num_workers=4) # batch size = 10*10=100\n",
    "# val_torch_dataset = PytorchFaceDataset(dataset_path, identities,\n",
    "#                                        max_images_per_identity=10, \n",
    "#                                        sample_indexes=val_indices)\n",
    "val_torch_dataset = PytorchFaceDataset(dataset_path, identities,\n",
    "                                       max_images_per_identity=10, \n",
    "                                       sample_indexes=val_indices,\n",
    "                                       classes_per_batch=10,   # each batch will pick 10 classes\n",
    "                                       samples_per_class=10) # each class has 10 samples\n",
    "# val_loader = val_torch_dataset.get_dataloader(batch_size=128, shuffle=False)\n",
    "val_loader = val_torch_dataset.get_dataloader(num_workers=4) # batch size = 10*10=100\n",
    "\n",
    "# Check shape\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "    print(\"Unique labels in this batch:\", len(set(labels.tolist())))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77, 112, 112, 3]) batch shape\n",
      "torch.Size([77]) labels shape\n"
     ]
    }
   ],
   "source": [
    "for batch, labels in train_loader:\n",
    "    print(batch.shape, 'batch shape')\n",
    "    print(labels.shape, 'labels shape')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import keras\n",
    "loss_metric = keras.metrics.Mean()\n",
    "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_accuracy_metric = keras.metrics.Mean() \n",
    "\n",
    "def pt_train_step(model, loss_fn, optimizer, train_batch):\n",
    "    model.zero_grad()\n",
    "\n",
    "    images, labels = train_batch  # Move to device if necessary\n",
    "\n",
    "    outputs = model(images)  # Forward pass\n",
    "    loss = loss_fn(labels, outputs)  # Compute loss\n",
    "\n",
    "    loss.backward()  # Backpropagation\n",
    "    grads = [param.grad for param in model.parameters()]\n",
    "\n",
    "    return loss.item(), grads\n",
    "\n",
    "def pt_valid_step(model, val_batch):\n",
    "    images, labels = val_batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(images)  # Forward pass\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    accuracy = (predicted_classes == labels).float().mean()\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_custom(mlp_model, loss_fn, opt, training_dataset, validation_dataset, train_step_fn, valid_step_fn, epochs):\n",
    "\n",
    "    # check if training is using GPU\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = config.device\n",
    "    print(f\"Device: {device}\")\n",
    "    mlp_model.to(device)\n",
    "    print(\"Training on GPU:\", next(mlp_model.parameters()).is_cuda)\n",
    "\n",
    "    epoch_losses = []\n",
    "    val_epoch_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        # Reset metrics for new epoch\n",
    "        loss_metric.reset_state()\n",
    "        val_accuracy_metric.reset_state()\n",
    "        \n",
    "        # Training loop\n",
    "        for images, labels in training_dataset:\n",
    "\n",
    "            loss, grads = train_step_fn(mlp_model, loss_fn, opt, train_batch=(images, labels))\n",
    "            opt.apply_gradients(zip(grads, mlp_model.trainable_variables))\n",
    "            \n",
    "            loss_metric.update_state(loss)\n",
    "\n",
    "        # Compute training loss and accuracy\n",
    "        avg_epoch_loss = float(loss_metric.result().cpu().numpy())\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad():  # Disable gradients for validation\n",
    "            for images, labels in validation_dataset:\n",
    "\n",
    "                acc = valid_step_fn(mlp_model, val_batch=(images, labels))\n",
    "                val_accuracy_metric.update_state(acc)\n",
    "\n",
    "        # Compute validation loss and accuracy\n",
    "        avg_val_acc = float(val_accuracy_metric.result().cpu().numpy())\n",
    "\n",
    "        # Store epoch results\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        val_epoch_acc.append(avg_val_acc)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch}: loss - {avg_epoch_loss:.4f}, \")\n",
    "\n",
    "        # for param in model.parameters():\n",
    "        #     print('grad:', param.grad)\n",
    "\n",
    "        # save checkpoint\n",
    "        # if epoch % 10 == 0:\n",
    "        print(f\"val_acc - {avg_val_acc:.4f}\")\n",
    "\n",
    "        checkpoint_dir = \"checkpoint\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "    return epoch_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n",
      "Training on GPU: True\n",
      "Epoch 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/home/jx1421/DL_TensorFlow_Imperial/DL_venv/lib64/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['sequential/conv2d/kernel', 'sequential/conv2d/bias', 'sequential/conv2d_1/kernel', 'sequential/conv2d_1/bias', 'sequential/conv2d_2/kernel', 'sequential/conv2d_2/bias', 'sequential/dense/kernel', 'sequential/dense/bias', 'sequential/dense_1/kernel', 'sequential/dense_1/bias', 'sequential/dense_2/kernel', 'sequential/dense_2/bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss - 8.9893, \n",
      "val_acc - 0.0001\n",
      "Epoch 1/10\n",
      "Epoch 1: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 2/10\n",
      "Epoch 2: loss - 8.9878, \n",
      "val_acc - 0.0000\n",
      "Epoch 3/10\n",
      "Epoch 3: loss - 8.9881, \n",
      "val_acc - 0.0000\n",
      "Epoch 4/10\n",
      "Epoch 4: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 5/10\n",
      "Epoch 5: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 6/10\n",
      "Epoch 6: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 7/10\n",
      "Epoch 7: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 8/10\n",
      "Epoch 8: loss - 8.9873, \n",
      "val_acc - 0.0000\n",
      "Epoch 9/10\n",
      "Epoch 9: loss - 8.9873, \n",
      "val_acc - 0.0000\n"
     ]
    }
   ],
   "source": [
    "# optimizer = keras.optimizers.SGD(learning_rate=0.05)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)  # If output has softmax\n",
    "\n",
    "\n",
    "epoch_losses = train_model_custom(model, loss_fn=loss_fn, opt=optimizer,\n",
    "                                            training_dataset=train_loader, \n",
    "                                            validation_dataset=val_loader, \n",
    "                                            train_step_fn=pt_train_step, \n",
    "                                            valid_step_fn=pt_valid_step,\n",
    "                                            epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
